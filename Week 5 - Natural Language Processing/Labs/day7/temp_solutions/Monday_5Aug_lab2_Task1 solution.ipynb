{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP From Scratch: Generating Names with a Character-Level RNN\n",
    "=============================================================\n",
    "\n",
    "**Author**: [Sean Robertson](https://github.com/spro),,, Note: this notebook is modified from the original one.\n",
    "\n",
    "We are still hand-crafting a small RNN with a few linear layers. The big\n",
    "difference is instead of predicting a category after reading in all the\n",
    "letters of a name, we input a category and output one letter at a time.\n",
    "Recurrently predicting characters to form language (this could also be\n",
    "done with words or other higher order constructs) is often referred to\n",
    "as a \\\"language model\\\".\n",
    "\n",
    "Preparing the Data\n",
    "------------------\n",
    "\n",
    "Data are saved in the directory 'data/names'. It includes 18 text files named as\n",
    "`[Language].txt`. Each file contains a bunch of names, one name per\n",
    "line, mostly romanized (but we still need to convert from Unicode to\n",
    "ASCII).\n",
    "\n",
    "We\\'ll end up with a dictionary of lists of names per language,\n",
    "`{language: [names ...]}`. The generic variables \\\"category\\\" and\n",
    "\\\"line\\\" (for language and name in our case) are used for later\n",
    "extensibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using your local machine, you should not comment 'f_path = 'data/names/*.txt'' and the rest of this block should be kept commented\n",
    "f_path = 'data/names/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you are using colab, please uncomment all the below lines then follow below instructions:\n",
    "# # You will be asked for a premesion to access your google drive, please acceept it\n",
    "# !git clone https://github.com/VictorCeballos/KAUST-AI-SS.git\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # - Locate /data/names/\n",
    "\n",
    "# f_path = '/content/KAUST-AI-SS/Week 5 - Natural Language Processing/Labs/day7/data/names/*.txt'\n",
    "\n",
    "# # - Providing the correct path will let you run the next block without an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Czech', 'German', 'Arabic', 'Japanese', 'Chinese', 'Vietnamese', 'Russian', 'French', 'Irish', 'English', 'Spanish', 'Greek', 'Italian', 'Portuguese', 'Scottish', 'Dutch', 'Korean', 'Polish']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# Build the category_lines dictionary, a list of lines per category\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles(f_path):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-1: Creating the Network\n",
    "====================\n",
    "\n",
    "This network extends the last tutorial\\'s RNN with an extra argument for the category tensor, which is concatenated\n",
    "along with the others. The category tensor is a one-hot vector just like\n",
    "the letter input.\n",
    "\n",
    "We will interpret the output as the probability of the next letter. When\n",
    "sampling, the most likely output letter is used as the next input\n",
    "letter.\n",
    "\n",
    "I added a second linear layer `o2o` (after combining hidden and output)\n",
    "to give it more muscle to work with. There\\'s also a dropout layer,\n",
    "which [randomly zeros parts of its\n",
    "input](https://arxiv.org/abs/1207.0580) with a given probability (here\n",
    "0.1) and is usually used to fuzz inputs to prevent overfitting. Here\n",
    "we\\'re using it towards the end of the network to purposely add some\n",
    "chaos and increase sampling variety.\n",
    "\n",
    "![](https://i.imgur.com/jzVrf7f.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) ### Following the architecture, i2h FC layer has in dim of the 3 tensors\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) ### i2o FC layer is same as i2h but different out dim\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size) ###  the last layer\n",
    "        # self.i2h = None #To Do\n",
    "        # self.i2o = None #To Do\n",
    "        # self.o2o = None #To Do\n",
    "        self.dropout = nn.Dropout(0.1) ### if there is time and not many people know it,,, explain it\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1) ### simple forward pass but concatenating all the tensors when it is needed\n",
    "        hidden = self.i2h(input_combined) \n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        # input_combined = None #To Do, Hint: use torch.cat\n",
    "        # hidden = None #To Do\n",
    "        # output = None #To Do\n",
    "        # output_combined = None #To Do, Hint: use torch.cat\n",
    "        # output = None #To Do\n",
    "        # output = None #To Do\n",
    "        # output = None #To Do\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
