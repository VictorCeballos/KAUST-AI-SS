{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6GkhIt8XJXW"
      },
      "source": [
        "This notebook is adapted from [Stanford CS224](http://snap.stanford.edu/class/cs224w-2021/) by Jure Leskovec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# Graph Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this notebook, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on two Open Graph Benchmark (OGB) datasets. These two datasets will be used to benchmark your model's performance on two different graph-based tasks: 1) node property prediction, predicting properties of single nodes and 2) graph property prediction, predicting properties of entire graphs or subgraphs.\n",
        "\n",
        "we will load and inspect the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides data loaders for each dataset but also model evaluators.\n",
        "\n",
        "Lastly, we will build our own graph neural network using PyTorch Geometric. We will then train and evaluate our model on the OGB node property prediction and graph property prediction tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vkP8pA1qBE5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric==2.4.0\n",
        "!pip install ogb"
      ],
      "metadata": {
        "id": "BEL00y7G1h61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6d22O6DqGSZ"
      },
      "source": [
        "Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itQRJZ9sZ5ck"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)\n",
        "\n",
        "# The PyG built-in GCNConv\n",
        "from torch_geometric.nn import GCNConv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) PyTorch Geometric (Datasets and Data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7vUmdNKCjA"
      },
      "source": [
        "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n",
        "\n",
        "In this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-o1P3r6hr2"
      },
      "source": [
        "## PyG Datasets\n",
        "\n",
        "The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT5qca3x6XpG"
      },
      "outputs": [],
      "source": [
        "enzymes_dataset = TUDataset(root='.', name='PROTEINS').shuffle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLm5vVYMAP2x"
      },
      "source": [
        "## Question 1: What is the number of classes and number of features in the ENZYMES dataset? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iF_Kyqr_JbY"
      },
      "outputs": [],
      "source": [
        "print(f'Dataset: {enzymes_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(enzymes_dataset)}')\n",
        "print(f'Number of features: {enzymes_dataset.num_features}')\n",
        "print(f'Number of classes: {enzymes_dataset.num_classes}')\n",
        "\n",
        "print(enzymes_dataset.x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKbzhHUAckZ"
      },
      "source": [
        "## PyG Data\n",
        "\n",
        "Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n",
        "\n",
        "For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIis9oTZAfs3"
      },
      "outputs": [],
      "source": [
        "print(enzymes_dataset[0])\n",
        "print('Graph with index {} has label {}'.format(200, enzymes_dataset[200].y.item()))\n",
        "print('Graph with index {} has {} number of edges'.format(200, enzymes_dataset[200].edge_index.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 3) GNN: Node Property Prediction\n",
        "\n",
        "In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n",
        "\n",
        "Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ibJ0ieoIwQM"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "demo_loader = DataLoader(enzymes_dataset[:4], batch_size=3, shuffle=False)\n",
        "\n",
        "print(enzymes_dataset[0])\n",
        "print(enzymes_dataset[1])\n",
        "\n",
        "print(enzymes_dataset[2])\n",
        "print(enzymes_dataset[3])\n",
        "print('============')\n",
        "for idx, batch in enumerate(demo_loader):\n",
        "    print(batch, batch.ptr)\n",
        "    print(batch.num_graphs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiW28gQB07ZQ"
      },
      "source": [
        "# Advanced Graph Batching\n",
        "\n",
        "What happened internally on the dataloader?. Since individual graph have represeneted their connetcivity according to the number of nodes in them a link on the graph 0 could read like [[0],[1]]\n",
        "another link on the graph 2 could have the very same connectivty. Howvere they are no inside the grap, and therefore represent a single connection on the agggeragted graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AlSFynk07ZQ"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "demo_loader2 = DataLoader(enzymes_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for idx, batch in enumerate(demo_loader2):\n",
        "    print(batch)\n",
        "    print(batch.num_graphs)\n",
        "    if idx > 20:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq0_R6PB07ZR"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import to_networkx\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = to_networkx(enzymes_dataset[35], to_undirected=True)\n",
        "\n",
        "# 3D spring layout\n",
        "pos = nx.spring_layout(G, dim=3, seed=0)\n",
        "\n",
        "# Extract node and edge positions from the layout\n",
        "node_xyz = np.array([pos[v] for v in sorted(G)])\n",
        "edge_xyz = np.array([(pos[u], pos[v]) for u, v in G.edges()])\n",
        "\n",
        "# Create the 3D figure\n",
        "fig = plt.figure(figsize=(16,16))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "# Suppress tick labels\n",
        "for dim in (ax.xaxis, ax.yaxis, ax.zaxis):\n",
        "    dim.set_ticks([])\n",
        "\n",
        "# Plot the nodes - alpha is scaled by \"depth\" automatically\n",
        "ax.scatter(*node_xyz.T, s=500, c=\"#0A047A\")\n",
        "\n",
        "# Plot the edges\n",
        "for vizedge in edge_xyz:\n",
        "    ax.plot(*vizedge.T, color=\"tab:gray\")\n",
        "\n",
        "# fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm-TIg_207ZR"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Create training, validation, and test sets\n",
        "train_idx = int(len(enzymes_dataset)*0.8)\n",
        "train_dataset = enzymes_dataset[:train_idx]\n",
        "val_dataset   = enzymes_dataset[train_idx:]\n",
        "\n",
        "print(f'Training set   = {len(train_dataset)} graphs')\n",
        "print(f'Validation set = {len(val_dataset)} graphs')\n",
        "\n",
        "# Create mini-batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print('\\nTrain loader:')\n",
        "for i, subgraph in enumerate(train_loader):\n",
        "    print(f' - Subgraph {i}: {subgraph}')\n",
        "\n",
        "print('\\nValidation loader:')\n",
        "for i, subgraph in enumerate(val_loader):\n",
        "    print(f' - Subgraph {i}: {subgraph}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUA815bNJ8w"
      },
      "source": [
        "## GCN Model\n",
        "\n",
        "Now we will implement our GCN model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgspXTYpNJLA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "\n",
        "class EnzymesGCN(torch.nn.Module):\n",
        "    \"\"\"GCN\"\"\"\n",
        "    def __init__(self, dim_h):\n",
        "        super(EnzymesGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(train_dataset.num_node_features, dim_h)\n",
        "        self.conv2 = GCNConv(dim_h, dim_h)\n",
        "        self.conv3 = GCNConv(dim_h, dim_h)\n",
        "        self.conv4 = GCNConv(dim_h, dim_h)\n",
        "        self.conv5 = GCNConv(dim_h, dim_h)\n",
        "        self.lin = Linear(dim_h, train_dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # Node embeddings\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv3(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv4(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv5(h, edge_index)\n",
        "        h = h.relu()\n",
        "\n",
        "        # Graph-level readout\n",
        "        hG = global_mean_pool(h, batch)\n",
        "\n",
        "        # Classifier\n",
        "        h = F.dropout(hG, p=0.5, training=self.training)\n",
        "        h = self.lin(h)\n",
        "\n",
        "        return hG, F.log_softmax(h, dim=1)\n",
        "\n",
        "print('GCN', EnzymesGCN)\n",
        "\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"GIN\"\"\"\n",
        "    def __init__(self, dim_h):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(train_dataset.num_node_features, dim_h),\n",
        "                       BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv3 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
        "        self.lin2 = Linear(dim_h*3, train_dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # Node embeddings\n",
        "        h1 = self.conv1(x, edge_index)\n",
        "        h2 = self.conv2(h1, edge_index)\n",
        "        h3 = self.conv3(h2, edge_index)\n",
        "\n",
        "        # Graph-level readout\n",
        "        h1 = global_add_pool(h1, batch)\n",
        "        h2 = global_add_pool(h2, batch)\n",
        "        h3 = global_add_pool(h3, batch)\n",
        "\n",
        "        # Concatenate graph embeddings\n",
        "        h = torch.cat((h1, h2, h3), dim=1)\n",
        "\n",
        "        # Classifier\n",
        "        h = self.lin1(h)\n",
        "        h = h.relu()\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return h, F.log_softmax(h, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF1hnHUhO81e"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader):\n",
        "    print('Train')\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=0.01)\n",
        "    epochs = 100\n",
        "\n",
        "\n",
        "    for epoch in range(epochs+1):\n",
        "        print('epoch', epoch)\n",
        "\n",
        "        total_loss = 0\n",
        "        acc = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        # Train on batches\n",
        "        model.train()\n",
        "        for data in train_loader:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _, out = model(data.x, data.edge_index, data.batch)\n",
        "            loss = criterion(out, data.y)\n",
        "            print(loss)\n",
        "            total_loss += loss / len(train_loader)\n",
        "            acc += accuracy(out.argmax(dim=1), data.y) / len(train_loader)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = test(model, val_loader)\n",
        "\n",
        "        # Print metrics every 10 epochs\n",
        "        print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n",
        "              f'| Train Acc: {acc*100:>5.2f}% '\n",
        "              f'| Val Loss: {val_loss:.2f} '\n",
        "              f'| Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(model, loader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    for data in loader:\n",
        "        _, out = model(data.x, data.edge_index, data.batch)\n",
        "        loss += criterion(out, data.y) / len(loader)\n",
        "        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gP4biL307ZS"
      },
      "outputs": [],
      "source": [
        "egcn = GIN(dim_h=32)\n",
        "egcn = train(egcn, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcx2EWu307ZS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}