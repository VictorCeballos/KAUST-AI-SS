{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weu0WzWVe0nP"
      },
      "source": [
        "This tutorial is adapted from [WikiNet — An Experiment in Recurrent Graph Neural Networks](https://medium.com/stanford-cs224w/wikinet-an-experiment-in-recurrent-graph-neural-networks-3f149676fbf3) by Alexander Hurtado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEi9i7wEkjIc"
      },
      "source": [
        "# WikiNet\n",
        "\n",
        "WikiNet tackles the target prediction problem on the Wikispeedia dataset. Namely, given a sequence of articles clicked by a player, the task is to predict the final target article the user is searching for. The following code is of the model definition, training, and evaluation for the experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While installing the dependencies you can try the game here: [wikispeedia](https://dlab.epfl.ch/wikispeedia/play/)\n",
        "\n",
        "More about the dataset details can be found [here](https://snap.stanford.edu/data/wikispeedia.html)"
      ],
      "metadata": {
        "id": "324S56XOPmB6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXXXMdUGp0hR"
      },
      "source": [
        "First, we begin by installing the necessary libraries and dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fq2m29soI-Y",
        "outputId": "f3413ac0-c94d-400b-9aab-688d608222e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=507268 sha256=e75adf742e2b53fb516f9cc480dcd36ee1f804dba1fbd8240b0186a992c60258\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1092566 sha256=501877d2a50cd855ae508aed0ee89fb85b8cc28ba0020a9192010362ad697511\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "Collecting class-resolver\n",
            "  Downloading class_resolver-0.4.3-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: class-resolver\n",
            "Successfully installed class-resolver-0.4.3\n",
            "--2024-07-09 20:36:15--  https://github.com/alexanderjhurtado/cs224w_wikinet/raw/main/colab_starter_pack/graph_with_features.gml.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/alexanderjhurtado/cs224w_wikinet/main/colab_starter_pack/graph_with_features.gml.zip [following]\n",
            "--2024-07-09 20:36:15--  https://raw.githubusercontent.com/alexanderjhurtado/cs224w_wikinet/main/colab_starter_pack/graph_with_features.gml.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6705796 (6.4M) [application/zip]\n",
            "Saving to: ‘graph_with_features.gml.zip’\n",
            "\n",
            "graph_with_features 100%[===================>]   6.39M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-07-09 20:36:16 (231 MB/s) - ‘graph_with_features.gml.zip’ saved [6705796/6705796]\n",
            "\n",
            "--2024-07-09 20:36:16--  https://github.com/alexanderjhurtado/cs224w_wikinet/raw/main/colab_starter_pack/paths_and_labels.tsv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/alexanderjhurtado/cs224w_wikinet/main/colab_starter_pack/paths_and_labels.tsv [following]\n",
            "--2024-07-09 20:36:16--  https://raw.githubusercontent.com/alexanderjhurtado/cs224w_wikinet/main/colab_starter_pack/paths_and_labels.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7353263 (7.0M) [text/plain]\n",
            "Saving to: ‘paths_and_labels.tsv’\n",
            "\n",
            "paths_and_labels.ts 100%[===================>]   7.01M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-07-09 20:36:16 (273 MB/s) - ‘paths_and_labels.tsv’ saved [7353263/7353263]\n",
            "\n",
            "Archive:  /content/graph_with_features.gml.zip\n",
            "  inflating: graph_with_features.gml  \n",
            "  inflating: __MACOSX/._graph_with_features.gml  \n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-geometric\n",
        "!pip install class-resolver\n",
        "\n",
        "!wget --no-cache https://github.com/alexanderjhurtado/cs224w_wikinet/raw/main/colab_starter_pack/graph_with_features.gml.zip\n",
        "!wget --no-cache https://github.com/alexanderjhurtado/cs224w_wikinet/raw/main/colab_starter_pack/paths_and_labels.tsv\n",
        "!unzip -o /content/graph_with_features.gml.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARdVxxwbp43X"
      },
      "source": [
        "Here, we import all libraries that will be used by the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zr95n5Vzoqq3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCN, GAT, GraphSAGE\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9e3vMVvfySQ",
        "outputId": "92712599-bebf-4b3f-e60b-24ea7276fee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-09 20:38:47--  https://github.com/alexanderjhurtado/cs224w_wikinet/blob/main/colab_starter_pack/graph_with_features.gml.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘graph_with_features.gml.zip.2’\n",
            "\n",
            "\r          graph_wit     [<=>                 ]       0  --.-KB/s               \rgraph_with_features     [ <=>                ] 280.93K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-07-09 20:38:48 (49.0 MB/s) - ‘graph_with_features.gml.zip.2’ saved [287669]\n",
            "\n",
            "--2024-07-09 20:38:48--  https://github.com/alexanderjhurtado/cs224w_wikinet/blob/main/colab_starter_pack/paths_and_labels.tsv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘paths_and_labels.tsv.2’\n",
            "\n",
            "paths_and_labels.ts     [ <=>                ] 160.49K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-07-09 20:38:48 (15.6 MB/s) - ‘paths_and_labels.tsv.2’ saved [164343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Getting the dataset\n",
        "!wget https://github.com/alexanderjhurtado/cs224w_wikinet/blob/main/colab_starter_pack/graph_with_features.gml.zip\n",
        "!wget https://github.com/alexanderjhurtado/cs224w_wikinet/blob/main/colab_starter_pack/paths_and_labels.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HJK41jk8osx9"
      },
      "outputs": [],
      "source": [
        "nx_graph = nx.read_gml('graph_with_features.gml')\n",
        "G = from_networkx(nx_graph, group_node_attrs=['out_degree', 'in_degree', 'category_multi_hot', 'article_embed'])\n",
        "path_data = pd.read_csv('paths_and_labels.tsv', sep='\\t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du205A0FEyuM",
        "outputId": "141f9f4d-4804-4ba2-d618-d3486960a195"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 119882], article=[4604], weight=[119882], x=[4604, 445])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.num_node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW2sTx-oE1tA",
        "outputId": "cdcc91e8-50d2-4581-9ee6-8b2331ceb6d8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.num_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2WOIPvKE6c2",
        "outputId": "4c02c0e2-1ef4-4653-bb6e-758917f57a33"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.num_edges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15hJoBh8E_GF",
        "outputId": "34bbac69-685a-406d-fbda-05136912ce47"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.num_edge_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFduMVv9FB7V",
        "outputId": "32575d91-aaa1-4644-9689-26e78146ac15"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G.x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o0BBQ7IF4sr",
        "outputId": "1a08687d-6087-4d62-f9ff-0f7acbbc5118"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4604, 445])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(G.edge_index.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpQycXgQFK9y",
        "outputId": "2fcec8db-434e-4122-c5c3-d919ae6dae21"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 119882])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGigWEo0rH2M"
      },
      "source": [
        "The following function will be called during training and evaluation to evaluate the model on the validation and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xL8mhtOrovBA"
      },
      "outputs": [],
      "source": [
        "def get_evaluation_metrics(model, device, dataloader, dataset_size):\n",
        "    model.eval()\n",
        "    avg_loss = 0\n",
        "    num_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(dataloader):\n",
        "            # get data\n",
        "            inputs, labels = data['indices'].to(device), data['label'].to(device)\n",
        "            outputs = model(inputs)\n",
        "            # get loss\n",
        "            loss = F.nll_loss(outputs, labels)\n",
        "            avg_loss += loss.item()\n",
        "            # get accuracy\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct = (pred == labels).sum()\n",
        "            num_correct += correct\n",
        "    acc = int(num_correct) / dataset_size\n",
        "    avg_loss /= dataset_size\n",
        "    return acc, avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZGu5CTXtQPO"
      },
      "source": [
        "This defines the dataset class we use to represent the path data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7tCnsYEvowvO"
      },
      "outputs": [],
      "source": [
        "class CustomPathDataset(Dataset):\n",
        "    def __init__(self, path_data):\n",
        "        self.x = path_data[0].apply(json.loads)\n",
        "        self.labels = path_data[1]\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.LongTensor(self.x[idx])\n",
        "        label = self.labels[idx]\n",
        "        sample = {\"indices\": x, \"label\": label}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XwpRS2VwnV4"
      },
      "source": [
        "Here, we set up the `train / val / test` split as `90 / 5 / 5`. Moreover, we define the hyperparameters, including the learning rate, the optimizer (Adam), and the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XmVP9ZVOED0K"
      },
      "outputs": [],
      "source": [
        "# get the dataset + splits\n",
        "dataset = CustomPathDataset(path_data)\n",
        "train_size = int(0.9 * len(dataset))\n",
        "test_size = int(0.05 * len(dataset))\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# set up for training + validation\n",
        "batch_size = 1024\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "validloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))['indices'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDLb0frlSIpl",
        "outputId": "99f284cf-5512-4991-e56f-04e4363865ee"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))['indices']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5h-U-eiSbhR",
        "outputId": "0243eb11-e88c-4da5-c7e5-d114d3c1731e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  -1,   -1,   -1,  ..., 1281, 1433, 3021],\n",
              "        [  -1,   -1,   -1,  ...,  978, 1281, 3011],\n",
              "        [  -1,   -1,   -1,  ...,  393, 1025,  357],\n",
              "        ...,\n",
              "        [  -1,   -1,   -1,  ..., 1036, 1349, 1354],\n",
              "        [  -1,   -1,   -1,  ..., 3823, 2022,  982],\n",
              "        [  -1,   -1,   -1,  ..., 1281, 3810,  128]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0phtzttgTCPW",
        "outputId": "503a9898-b089-4ca3-c4da-8f10ee7ffe22"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'indices': tensor([[  -1,   -1,   -1,  ..., 3335, 1246, 3780],\n",
              "         [  -1,   -1,   -1,  ..., 4297, 4017, 1119],\n",
              "         [  -1,   -1,   -1,  ..., 2949, 2098, 2114],\n",
              "         ...,\n",
              "         [  -1,   -1,   -1,  ..., 4091, 3458, 2205],\n",
              "         [  -1,   -1,   -1,  ...,  915,  907, 3196],\n",
              "         [  -1,   -1,   -1,  ..., 1528,  590, 1238]]),\n",
              " 'label': tensor([ 899, 3797, 2554,  ..., 1091, 4362, 1428])}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))['indices'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9R8JE6MSyAo",
        "outputId": "3f4cdac9-0ec3-4e27-cfce-94af9da0508e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
              "          -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
              "          -1,   -1,   -1,   -1,   -1,   -1, 1694, 4297])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1bfm4i3-3v9"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLISGR7dtTkk"
      },
      "source": [
        "This is the class definition for the baseline model, an LSTM. Run this cell to be able to train the baseline model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "MSMEyv6Ytcid"
      },
      "outputs": [],
      "source": [
        "class Baseline(torch.nn.Module):\n",
        "    def __init__(self, graph, device, sequence_path_length=32, lstm_hidden_size=32):\n",
        "        super().__init__()\n",
        "        # print(\"graph.x.shape\", graph.x.shape)\n",
        "        self.graphX = graph.x.to(device)\n",
        "\n",
        "        self.graphEdgeIndex = graph.edge_index.to(device)\n",
        "\n",
        "        self.lstm_input_size = self.graphX.shape[1]\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_size,\n",
        "                            hidden_size=lstm_hidden_size,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.batch_norm_lstm = nn.BatchNorm1d(sequence_path_length)\n",
        "\n",
        "        self.pred_head = nn.Linear(lstm_hidden_size, self.graphX.shape[0])\n",
        "\n",
        "    def forward(self, indices):\n",
        "        node_emb = self.graphX\n",
        "        node_emb_with_padding = torch.cat([node_emb, torch.zeros((1, self.lstm_input_size)).to(device)])\n",
        "        paths = node_emb_with_padding[indices]\n",
        "        paths = self.batch_norm_lstm(paths)\n",
        "        _, (h_n, _) = self.lstm(paths)\n",
        "        predictions = self.pred_head(torch.squeeze(h_n))\n",
        "        return F.log_softmax(predictions, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "vFAmfEgl-1rm"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Baseline(G, device).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qc3D6BX-1rn"
      },
      "source": [
        "This is the training script. We train the model for 20 epochs and print training loss, validation loss, validation accuracy, and time spent for each epoch.\n",
        "\n",
        "Moreover, we train by running one batch through the model at a time and using the Negative Log Likelihood loss function. We also save the model weights for the best validation accuracy we see after an epoch. These weights will be used in the evaluation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjG-xLlf-1rn",
        "outputId": "d2631a1e-7e3a-4043-9685-2f491cdbbfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training Loss: 0.007172050284736\n",
            "Validation accuracy: 0.11267056530214425\n",
            "Validation loss: 0.007454270368431047\n",
            "Time elapsed: 37.720823764801025\n",
            "\n",
            "Epoch: 2\n",
            "Training Loss: 0.005631540172583682\n",
            "Validation accuracy: 0.14892787524366471\n",
            "Validation loss: 0.006440677605641981\n",
            "Time elapsed: 35.28937840461731\n",
            "\n",
            "Epoch: 3\n",
            "Training Loss: 0.004937904951513219\n",
            "Validation accuracy: 0.16803118908382067\n",
            "Validation loss: 0.005960288057085599\n",
            "Time elapsed: 36.43272161483765\n",
            "\n",
            "Epoch: 4\n",
            "Training Loss: 0.004559457469979362\n",
            "Validation accuracy: 0.18323586744639375\n",
            "Validation loss: 0.0056781476933588995\n",
            "Time elapsed: 35.318153619766235\n",
            "\n",
            "Epoch: 5\n",
            "Training Loss: 0.0043047392508307625\n",
            "Validation accuracy: 0.1968810916179337\n",
            "Validation loss: 0.005473834775809424\n",
            "Time elapsed: 37.035537004470825\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MODEL_WEIGHT_PATH = \"model_weights.pth\"\n",
        "\n",
        "best_acc = 0\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "validation_accs = []\n",
        "model.train()\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    print('Epoch:', epoch+1)\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    start_time = time.time()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data['indices'].to(device), data['label'].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = F.nll_loss(outputs, labels)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # validate epoch and print results\n",
        "    training_losses.append(epoch_loss / train_size)\n",
        "    print('Training Loss:', training_losses[-1])\n",
        "    acc, valid_loss = get_evaluation_metrics(model, device, validloader, val_size)\n",
        "    validation_losses.append(valid_loss)\n",
        "    validation_accs.append(acc)\n",
        "    if acc > best_acc:\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHT_PATH)\n",
        "        best_acc = acc\n",
        "    print(\"Validation accuracy:\", acc)\n",
        "    print(\"Validation loss:\", valid_loss)\n",
        "    print('Time elapsed:', time.time() - start_time)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA4t8Tm9-1ro"
      },
      "source": [
        "This code runs evaluation on the test dataset. In particular, it uses the weights from the best validation accuracy to obtain the test accuracy.\n",
        "\n",
        "This cell will print out the \"loss\" and accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlaQZ5Ks-1ro",
        "outputId": "be3b52dd-4f9f-4258-b8ae-263745270503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.20124804992199688\n",
            "Test loss: 0.0055526839031630115\n"
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load(MODEL_WEIGHT_PATH))\n",
        "model.eval()\n",
        "acc, test_loss = get_evaluation_metrics(model, device, testloader, test_size)\n",
        "print(\"Test accuracy:\", acc)\n",
        "print(\"Test loss:\", test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "\n"
      ],
      "metadata": {
        "id": "E6vTcdZ1Xynf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGDj7r4Z-wms"
      },
      "source": [
        "## Graph Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysVSRJp_uGhR"
      },
      "source": [
        "This is the class definition for the Graph Neural Network - based model.If you would like to use GCN or GAT, simply use `self.gnn = GraphSAGE(...)` with `self.gnn = GCN(...)` or `self.gnn = GAT(...)`, respectively. The arguments are the same for all 3 models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "U6nU8MS_oyC7"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, graph, device, sequence_path_length=32, gnn_hidden_size=128, node_embed_size=64, lstm_hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.graphX = graph.x.to(device)\n",
        "        self.graphEdgeIndex = graph.edge_index.to(device)\n",
        "\n",
        "        self.gnn = GraphSAGE(in_channels=self.graphX.shape[1],\n",
        "                       hidden_channels=gnn_hidden_size,\n",
        "                       num_layers=3,\n",
        "                       out_channels=node_embed_size,\n",
        "                       dropout=0.1)\n",
        "\n",
        "        self.batch_norm_lstm = nn.BatchNorm1d(sequence_path_length)\n",
        "        self.batch_norm_linear = nn.BatchNorm1d(lstm_hidden_size)\n",
        "        self.lstm_input_size = node_embed_size\n",
        "        self.lstm = nn.LSTM(input_size=self.lstm_input_size,\n",
        "                            hidden_size=lstm_hidden_size,\n",
        "                            batch_first=True)\n",
        "        self.pred_head = nn.Linear(lstm_hidden_size, self.graphX.shape[0])\n",
        "\n",
        "    def forward(self, indices):\n",
        "        node_emb = self.gnn(self.graphX, self.graphEdgeIndex)\n",
        "        node_emb_with_padding = torch.cat([node_emb, torch.zeros((1, self.lstm_input_size)).to(device)])\n",
        "        paths = node_emb_with_padding[indices]\n",
        "        paths = self.batch_norm_lstm(paths)\n",
        "        _, (h_n, _) = self.lstm(paths)\n",
        "        h_n = self.batch_norm_linear(torch.squeeze(h_n))\n",
        "        predictions = self.pred_head(h_n)\n",
        "        return F.log_softmax(predictions, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "sR5HTLUgo0lX"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Model(G, device).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4qpQl1YxGUK"
      },
      "source": [
        "We train by running one batch through the model at a time and using the Negative Log Likelihood loss function. We also save the model weights for the best validation accuracy we see after an epoch. These weights will be used in the evaluation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxsa2R8hp9_Q",
        "outputId": "d7cbfdf0-3487-414e-d4a1-80222b8d2f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training Loss: 0.006116383719465971\n",
            "Validation accuracy: 0.15789473684210525\n",
            "Validation loss: 0.006488299788090221\n",
            "Time elapsed: 39.034395694732666\n",
            "\n",
            "Epoch: 2\n",
            "Training Loss: 0.004774074928028133\n",
            "Validation accuracy: 0.19922027290448344\n",
            "Validation loss: 0.005681933761804889\n",
            "Time elapsed: 37.760902643203735\n",
            "\n",
            "Epoch: 3\n",
            "Training Loss: 0.004126869289601351\n",
            "Validation accuracy: 0.22690058479532163\n",
            "Validation loss: 0.005213679114745142\n",
            "Time elapsed: 37.95190382003784\n",
            "\n",
            "Epoch: 4\n",
            "Training Loss: 0.0037679500016150765\n",
            "Validation accuracy: 0.253411306042885\n",
            "Validation loss: 0.004903466706155104\n",
            "Time elapsed: 38.64852023124695\n",
            "\n",
            "Epoch: 5\n",
            "Training Loss: 0.003509110148529424\n",
            "Validation accuracy: 0.2764132553606238\n",
            "Validation loss: 0.004712960687529506\n",
            "Time elapsed: 37.983099937438965\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_acc = 0\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "validation_accs = []\n",
        "model.train()\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    print('Epoch:', epoch+1)\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    start_time = time.time()\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data['indices'].to(device), data['label'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = F.nll_loss(outputs, labels)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # validate epoch and print results\n",
        "    training_losses.append(epoch_loss / train_size)\n",
        "    print('Training Loss:', training_losses[-1])\n",
        "    acc, valid_loss = get_evaluation_metrics(model, device, validloader, val_size)\n",
        "    validation_losses.append(valid_loss)\n",
        "    validation_accs.append(acc)\n",
        "    if acc > best_acc:\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHT_PATH)\n",
        "        best_acc = acc\n",
        "    print(\"Validation accuracy:\", acc)\n",
        "    print(\"Validation loss:\", valid_loss)\n",
        "    print('Time elapsed:', time.time() - start_time)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xig9d5Kxxilv"
      },
      "source": [
        "This code runs evaluation on the test dataset. In particular, it uses the weights from the best validation accuracy to obtain the test accuracy.\n",
        "\n",
        "This cell will print out the \"loss\" and accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_sObjK9o5_4",
        "outputId": "fe1b29c0-0c4f-4738-a102-fa5f59b08737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.2578003120124805\n",
            "Test loss: 0.004841907719926045\n"
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load(MODEL_WEIGHT_PATH))\n",
        "model.eval()\n",
        "acc, test_loss = get_evaluation_metrics(model, device, testloader, test_size)\n",
        "print(\"Test accuracy:\", acc)\n",
        "print(\"Test loss:\", test_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj6yrTYeDO89"
      },
      "source": [
        "Graph Recurrent Neural Network performed better."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYmRAtACTsO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}