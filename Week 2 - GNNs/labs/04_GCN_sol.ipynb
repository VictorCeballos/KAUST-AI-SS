{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6GkhIt8XJXW"
      },
      "source": [
        "This notebook is adapted from [Stanford CS224](http://snap.stanford.edu/class/cs224w-2021/) by Jure Leskovec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# Graph Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this notebook, we will work to construct our own graph neural network using PyTorch Geometric (PyG) and then apply that model on two Open Graph Benchmark (OGB) datasets. These two datasets will be used to benchmark your model's performance on two different graph-based tasks: 1) node property prediction, predicting properties of single nodes and 2) graph property prediction, predicting properties of entire graphs or subgraphs.\n",
        "\n",
        "we will load and inspect the Open Graph Benchmark (OGB) datasets by using the `ogb` package. OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. The `ogb` package not only provides data loaders for each dataset but also model evaluators.\n",
        "\n",
        "Lastly, we will build our own graph neural network using PyTorch Geometric. We will then train and evaluate our model on the OGB node property prediction and graph property prediction tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkP8pA1qBE5",
        "outputId": "7aaaa4c3-d4db-4d69-cc07-1812efe96d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version 2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"PyTorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEL00y7G1h61",
        "outputId": "1c8b708c-2c79-45ea-c689-64d1c3478c58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.25.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->ogb)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6d22O6DqGSZ"
      },
      "source": [
        "Download the necessary packages for PyG. Make sure that your version of torch matches the output from the cell above. In case of any issues, more information can be found on the [PyG's installation page](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itQRJZ9sZ5ck",
        "outputId": "97c00739-43ff-4d62-f259-e3dec89e4baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "print(torch.__version__)\n",
        "\n",
        "# The PyG built-in GCNConv\n",
        "from torch_geometric.nn import GCNConv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) PyTorch Geometric (Datasets and Data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7vUmdNKCjA"
      },
      "source": [
        "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n",
        "\n",
        "In this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-o1P3r6hr2"
      },
      "source": [
        "## PyG Datasets\n",
        "\n",
        "The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5qca3x6XpG",
        "outputId": "b5d64619-19f1-4116-cf82-ae2e695dcc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "enzymes_dataset = TUDataset(root='.', name='PROTEINS').shuffle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLm5vVYMAP2x"
      },
      "source": [
        "## Question 1: What is the number of classes and number of features in the ENZYMES dataset? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iF_Kyqr_JbY",
        "outputId": "06e9a76e-90e1-49bf-f174-877bc550626a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: PROTEINS(1113):\n",
            "======================\n",
            "Number of graphs: 1113\n",
            "Number of features: 3\n",
            "Number of classes: 2\n",
            "tensor([1., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "print(f'Dataset: {enzymes_dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(enzymes_dataset)}')\n",
        "print(f'Number of features: {enzymes_dataset.num_features}')\n",
        "print(f'Number of classes: {enzymes_dataset.num_classes}')\n",
        "\n",
        "print(enzymes_dataset.x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKbzhHUAckZ"
      },
      "source": [
        "## PyG Data\n",
        "\n",
        "Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n",
        "\n",
        "For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIis9oTZAfs3",
        "outputId": "460fa200-567a-48a7-d92f-38afec7459ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 12], x=[4, 3], y=[1])\n",
            "Graph with index 200 has label 0\n",
            "Graph with index 200 has 162 number of edges\n"
          ]
        }
      ],
      "source": [
        "print(enzymes_dataset[0])\n",
        "print('Graph with index {} has label {}'.format(200, enzymes_dataset[200].y.item()))\n",
        "print('Graph with index {} has {} number of edges'.format(200, enzymes_dataset[200].edge_index.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 3) GNN: Node Property Prediction\n",
        "\n",
        "In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n",
        "\n",
        "Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibJ0ieoIwQM",
        "outputId": "09309690-14a3-4ec9-e3b7-190b435db43b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 12], x=[4, 3], y=[1])\n",
            "Data(edge_index=[2, 142], x=[40, 3], y=[1])\n",
            "Data(edge_index=[2, 78], x=[21, 3], y=[1])\n",
            "Data(edge_index=[2, 848], x=[285, 3], y=[1])\n",
            "============\n",
            "DataBatch(edge_index=[2, 232], x=[65, 3], y=[3], batch=[65], ptr=[4]) tensor([ 0,  4, 44, 65])\n",
            "3\n",
            "DataBatch(edge_index=[2, 848], x=[285, 3], y=[1], batch=[285], ptr=[2]) tensor([  0, 285])\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "demo_loader = DataLoader(enzymes_dataset[:4], batch_size=3, shuffle=False)\n",
        "\n",
        "print(enzymes_dataset[0])\n",
        "print(enzymes_dataset[1])\n",
        "\n",
        "print(enzymes_dataset[2])\n",
        "print(enzymes_dataset[3])\n",
        "print('============')\n",
        "for idx, batch in enumerate(demo_loader):\n",
        "    print(batch, batch.ptr)\n",
        "    print(batch.num_graphs)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiW28gQB07ZQ"
      },
      "source": [
        "# Advanced Graph Batching\n",
        "\n",
        "What happened internally on the dataloader?. Since individual graph have represeneted their connetcivity according to the number of nodes in them a link on the graph 0 could read like [[0],[1]]\n",
        "another link on the graph 2 could have the very same connectivty. Howvere they are no inside the grap, and therefore represent a single connection on the agggeragted graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db34f12a-7727-4eca-da78-26277e4eccf8",
        "id": "_AlSFynk07ZQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataBatch(edge_index=[2, 4818], x=[1267, 3], y=[32], batch=[1267], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4298], x=[1128, 3], y=[32], batch=[1128], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 7450], x=[2087, 3], y=[32], batch=[2087], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3496], x=[931, 3], y=[32], batch=[931], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4014], x=[1110, 3], y=[32], batch=[1110], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4030], x=[1078, 3], y=[32], batch=[1078], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3934], x=[1037, 3], y=[32], batch=[1037], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5068], x=[1379, 3], y=[32], batch=[1379], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3362], x=[888, 3], y=[32], batch=[888], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3678], x=[962, 3], y=[32], batch=[962], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4638], x=[1236, 3], y=[32], batch=[1236], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5340], x=[1408, 3], y=[32], batch=[1408], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 6022], x=[1654, 3], y=[32], batch=[1654], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5578], x=[1408, 3], y=[32], batch=[1408], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4860], x=[1321, 3], y=[32], batch=[1321], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4576], x=[1183, 3], y=[32], batch=[1183], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 4344], x=[1201, 3], y=[32], batch=[1201], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3486], x=[1000, 3], y=[32], batch=[1000], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5170], x=[1415, 3], y=[32], batch=[1415], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5592], x=[1569, 3], y=[32], batch=[1569], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 3900], x=[1042, 3], y=[32], batch=[1042], ptr=[33])\n",
            "32\n",
            "DataBatch(edge_index=[2, 5270], x=[1356, 3], y=[32], batch=[1356], ptr=[33])\n",
            "32\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "demo_loader2 = DataLoader(enzymes_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for idx, batch in enumerate(demo_loader2):\n",
        "    print(batch)\n",
        "    print(batch.num_graphs)\n",
        "    if idx > 20:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tq0_R6PB07ZR",
        "outputId": "ba2c2921-44fd-42b3-c74d-649ace6731fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch_geometric.utils import to_networkx\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G = to_networkx(enzymes_dataset[35], to_undirected=True)\n",
        "\n",
        "# 3D spring layout\n",
        "pos = nx.spring_layout(G, dim=3, seed=0)\n",
        "\n",
        "# Extract node and edge positions from the layout\n",
        "node_xyz = np.array([pos[v] for v in sorted(G)])\n",
        "edge_xyz = np.array([(pos[u], pos[v]) for u, v in G.edges()])\n",
        "\n",
        "# Create the 3D figure\n",
        "fig = plt.figure(figsize=(16,16))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "\n",
        "# Suppress tick labels\n",
        "for dim in (ax.xaxis, ax.yaxis, ax.zaxis):\n",
        "    dim.set_ticks([])\n",
        "\n",
        "# Plot the nodes - alpha is scaled by \"depth\" automatically\n",
        "ax.scatter(*node_xyz.T, s=500, c=\"#0A047A\")\n",
        "\n",
        "# Plot the edges\n",
        "for vizedge in edge_xyz:\n",
        "    ax.plot(*vizedge.T, color=\"tab:gray\")\n",
        "\n",
        "# fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm-TIg_207ZR",
        "outputId": "d73d7113-a079-4529-feb7-23a0e3d8e543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set   = 890 graphs\n",
            "Validation set = 223 graphs\n",
            "\n",
            "Train loader:\n",
            " - Subgraph 0: DataBatch(edge_index=[2, 5114], x=[1361, 3], y=[32], batch=[1361], ptr=[33])\n",
            " - Subgraph 1: DataBatch(edge_index=[2, 6344], x=[1681, 3], y=[32], batch=[1681], ptr=[33])\n",
            " - Subgraph 2: DataBatch(edge_index=[2, 3782], x=[983, 3], y=[32], batch=[983], ptr=[33])\n",
            " - Subgraph 3: DataBatch(edge_index=[2, 4380], x=[1151, 3], y=[32], batch=[1151], ptr=[33])\n",
            " - Subgraph 4: DataBatch(edge_index=[2, 4482], x=[1163, 3], y=[32], batch=[1163], ptr=[33])\n",
            " - Subgraph 5: DataBatch(edge_index=[2, 3862], x=[986, 3], y=[32], batch=[986], ptr=[33])\n",
            " - Subgraph 6: DataBatch(edge_index=[2, 3760], x=[1018, 3], y=[32], batch=[1018], ptr=[33])\n",
            " - Subgraph 7: DataBatch(edge_index=[2, 3490], x=[909, 3], y=[32], batch=[909], ptr=[33])\n",
            " - Subgraph 8: DataBatch(edge_index=[2, 4434], x=[1207, 3], y=[32], batch=[1207], ptr=[33])\n",
            " - Subgraph 9: DataBatch(edge_index=[2, 4446], x=[1245, 3], y=[32], batch=[1245], ptr=[33])\n",
            " - Subgraph 10: DataBatch(edge_index=[2, 7592], x=[1960, 3], y=[32], batch=[1960], ptr=[33])\n",
            " - Subgraph 11: DataBatch(edge_index=[2, 5026], x=[1310, 3], y=[32], batch=[1310], ptr=[33])\n",
            " - Subgraph 12: DataBatch(edge_index=[2, 4708], x=[1312, 3], y=[32], batch=[1312], ptr=[33])\n",
            " - Subgraph 13: DataBatch(edge_index=[2, 4076], x=[1056, 3], y=[32], batch=[1056], ptr=[33])\n",
            " - Subgraph 14: DataBatch(edge_index=[2, 5062], x=[1292, 3], y=[32], batch=[1292], ptr=[33])\n",
            " - Subgraph 15: DataBatch(edge_index=[2, 4266], x=[1090, 3], y=[32], batch=[1090], ptr=[33])\n",
            " - Subgraph 16: DataBatch(edge_index=[2, 5244], x=[1344, 3], y=[32], batch=[1344], ptr=[33])\n",
            " - Subgraph 17: DataBatch(edge_index=[2, 5362], x=[1376, 3], y=[32], batch=[1376], ptr=[33])\n",
            " - Subgraph 18: DataBatch(edge_index=[2, 4260], x=[1180, 3], y=[32], batch=[1180], ptr=[33])\n",
            " - Subgraph 19: DataBatch(edge_index=[2, 3834], x=[1084, 3], y=[32], batch=[1084], ptr=[33])\n",
            " - Subgraph 20: DataBatch(edge_index=[2, 3766], x=[1032, 3], y=[32], batch=[1032], ptr=[33])\n",
            " - Subgraph 21: DataBatch(edge_index=[2, 3838], x=[1010, 3], y=[32], batch=[1010], ptr=[33])\n",
            " - Subgraph 22: DataBatch(edge_index=[2, 5376], x=[1490, 3], y=[32], batch=[1490], ptr=[33])\n",
            " - Subgraph 23: DataBatch(edge_index=[2, 4736], x=[1268, 3], y=[32], batch=[1268], ptr=[33])\n",
            " - Subgraph 24: DataBatch(edge_index=[2, 3864], x=[1048, 3], y=[32], batch=[1048], ptr=[33])\n",
            " - Subgraph 25: DataBatch(edge_index=[2, 4792], x=[1357, 3], y=[32], batch=[1357], ptr=[33])\n",
            " - Subgraph 26: DataBatch(edge_index=[2, 4310], x=[1172, 3], y=[32], batch=[1172], ptr=[33])\n",
            " - Subgraph 27: DataBatch(edge_index=[2, 5706], x=[1556, 3], y=[26], batch=[1556], ptr=[27])\n",
            "\n",
            "Validation loader:\n",
            " - Subgraph 0: DataBatch(edge_index=[2, 3798], x=[1054, 3], y=[32], batch=[1054], ptr=[33])\n",
            " - Subgraph 1: DataBatch(edge_index=[2, 4924], x=[1221, 3], y=[32], batch=[1221], ptr=[33])\n",
            " - Subgraph 2: DataBatch(edge_index=[2, 4096], x=[1145, 3], y=[32], batch=[1145], ptr=[33])\n",
            " - Subgraph 3: DataBatch(edge_index=[2, 4762], x=[1364, 3], y=[32], batch=[1364], ptr=[33])\n",
            " - Subgraph 4: DataBatch(edge_index=[2, 4670], x=[1309, 3], y=[32], batch=[1309], ptr=[33])\n",
            " - Subgraph 5: DataBatch(edge_index=[2, 6040], x=[1694, 3], y=[32], batch=[1694], ptr=[33])\n",
            " - Subgraph 6: DataBatch(edge_index=[2, 3886], x=[1043, 3], y=[31], batch=[1043], ptr=[32])\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Create training, validation, and test sets\n",
        "train_idx = int(len(enzymes_dataset)*0.8)\n",
        "train_dataset = enzymes_dataset[:train_idx]\n",
        "val_dataset   = enzymes_dataset[train_idx:]\n",
        "\n",
        "print(f'Training set   = {len(train_dataset)} graphs')\n",
        "print(f'Validation set = {len(val_dataset)} graphs')\n",
        "\n",
        "# Create mini-batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print('\\nTrain loader:')\n",
        "for i, subgraph in enumerate(train_loader):\n",
        "    print(f' - Subgraph {i}: {subgraph}')\n",
        "\n",
        "print('\\nValidation loader:')\n",
        "for i, subgraph in enumerate(val_loader):\n",
        "    print(f' - Subgraph {i}: {subgraph}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUA815bNJ8w"
      },
      "source": [
        "## GCN Model\n",
        "\n",
        "Now we will implement our GCN model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IgspXTYpNJLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324ebb6c-3b59-41e1-8f16-ceb833550798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN <class '__main__.EnzymesGCN'>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "\n",
        "class EnzymesGCN(torch.nn.Module):\n",
        "    \"\"\"GCN\"\"\"\n",
        "    def __init__(self, dim_h):\n",
        "        super(EnzymesGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(train_dataset.num_node_features, dim_h)\n",
        "        self.conv2 = GCNConv(dim_h, dim_h)\n",
        "        self.conv3 = GCNConv(dim_h, dim_h)\n",
        "        self.conv4 = GCNConv(dim_h, dim_h)\n",
        "        self.conv5 = GCNConv(dim_h, dim_h)\n",
        "        self.lin = Linear(dim_h, train_dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # Node embeddings\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv3(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv4(h, edge_index)\n",
        "        h = h.relu()\n",
        "        h = self.conv5(h, edge_index)\n",
        "        h = h.relu()\n",
        "\n",
        "        # Graph-level readout\n",
        "        hG = global_mean_pool(h, batch)\n",
        "\n",
        "        # Classifier\n",
        "        h = F.dropout(hG, p=0.5, training=self.training)\n",
        "        h = self.lin(h)\n",
        "\n",
        "        return hG, F.log_softmax(h, dim=1)\n",
        "\n",
        "print('GCN', EnzymesGCN)\n",
        "\n",
        "\n",
        "class GIN(torch.nn.Module):\n",
        "    \"\"\"GIN\"\"\"\n",
        "    def __init__(self, dim_h):\n",
        "        super(GIN, self).__init__()\n",
        "        self.conv1 = GINConv(\n",
        "            Sequential(Linear(train_dataset.num_node_features, dim_h),\n",
        "                       BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv2 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.conv3 = GINConv(\n",
        "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
        "                       Linear(dim_h, dim_h), ReLU()))\n",
        "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
        "        self.lin2 = Linear(dim_h*3, train_dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # Node embeddings\n",
        "        h1 = self.conv1(x, edge_index)\n",
        "        h2 = self.conv2(h1, edge_index)\n",
        "        h3 = self.conv3(h2, edge_index)\n",
        "\n",
        "        # Graph-level readout\n",
        "        h1 = global_add_pool(h1, batch)\n",
        "        h2 = global_add_pool(h2, batch)\n",
        "        h3 = global_add_pool(h3, batch)\n",
        "\n",
        "        # Concatenate graph embeddings\n",
        "        h = torch.cat((h1, h2, h3), dim=1)\n",
        "\n",
        "        # Classifier\n",
        "        h = self.lin1(h)\n",
        "        h = h.relu()\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.lin2(h)\n",
        "\n",
        "        return h, F.log_softmax(h, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FF1hnHUhO81e"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader):\n",
        "    print('Train')\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=0.01)\n",
        "    epochs = 100\n",
        "\n",
        "\n",
        "    for epoch in range(epochs+1):\n",
        "        print('epoch', epoch)\n",
        "\n",
        "        total_loss = 0\n",
        "        acc = 0\n",
        "        val_loss = 0\n",
        "        val_acc = 0\n",
        "\n",
        "        # Train on batches\n",
        "        model.train()\n",
        "        for data in train_loader:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _, out = model(data.x, data.edge_index, data.batch)\n",
        "            loss = criterion(out, data.y)\n",
        "            print(loss)\n",
        "            total_loss += loss / len(train_loader)\n",
        "            acc += accuracy(out.argmax(dim=1), data.y) / len(train_loader)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = test(model, val_loader)\n",
        "\n",
        "        # Print metrics every 10 epochs\n",
        "        print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} '\n",
        "              f'| Train Acc: {acc*100:>5.2f}% '\n",
        "              f'| Val Loss: {val_loss:.2f} '\n",
        "              f'| Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def test(model, loader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "\n",
        "    for data in loader:\n",
        "        _, out = model(data.x, data.edge_index, data.batch)\n",
        "        loss += criterion(out, data.y) / len(loader)\n",
        "        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "def accuracy(pred_y, y):\n",
        "    \"\"\"Calculate accuracy.\"\"\"\n",
        "    return ((pred_y == y).sum() / len(y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gP4biL307ZS",
        "outputId": "1463c8ba-49dc-4948-f74d-c3db8fc051eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "epoch 0\n",
            "tensor(1.5061, grad_fn=<NllLossBackward0>)\n",
            "tensor(15.6804, grad_fn=<NllLossBackward0>)\n",
            "tensor(33.5037, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9632, grad_fn=<NllLossBackward0>)\n",
            "tensor(7.3456, grad_fn=<NllLossBackward0>)\n",
            "tensor(3.4095, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.9697, grad_fn=<NllLossBackward0>)\n",
            "tensor(2.1793, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.9345, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.4646, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7133, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.7669, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1095, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6185, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6273, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5343, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5760, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6250, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7751, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6410, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5881, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0280, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6670, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6192, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8049, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5749, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0734, grad_fn=<NllLossBackward0>)\n",
            "Epoch   0 | Train Loss: 3.18 | Train Acc: 57.89% | Val Loss: 7.84 | Val Acc: 56.44%\n",
            "epoch 1\n",
            "tensor(1.5864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7485, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7088, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0566, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8458, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5138, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8774, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6411, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5086, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5381, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7431, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7041, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0988, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.5099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7751, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6625, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6657, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6157, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6811, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6229, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6182, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5557, grad_fn=<NllLossBackward0>)\n",
            "Epoch   1 | Train Loss: 0.77 | Train Acc: 60.09% | Val Loss: 0.67 | Val Acc: 63.21%\n",
            "epoch 2\n",
            "tensor(0.6252, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6549, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6503, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7690, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6143, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6057, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7274, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6079, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5594, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6436, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6981, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6315, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6946, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5795, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5815, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4455, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7056, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5478, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5249, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6182, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4764, grad_fn=<NllLossBackward0>)\n",
            "Epoch   2 | Train Loss: 0.64 | Train Acc: 64.89% | Val Loss: 0.65 | Val Acc: 68.63%\n",
            "epoch 3\n",
            "tensor(0.5918, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7499, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6992, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7004, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5883, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5522, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5114, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5953, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5885, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6055, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5889, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5532, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5203, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6250, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6168, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7233, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5400, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6160, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5959, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6194, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4939, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7671, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5994, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5212, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
            "Epoch   3 | Train Loss: 0.60 | Train Acc: 65.70% | Val Loss: 0.60 | Val Acc: 69.57%\n",
            "epoch 4\n",
            "tensor(0.6217, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6077, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5116, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4464, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3874, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6582, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7058, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5563, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4999, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6680, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5651, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5447, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6408, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7807, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6615, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5736, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4560, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8250, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5505, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5560, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5603, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
            "Epoch   4 | Train Loss: 0.61 | Train Acc: 67.90% | Val Loss: 0.60 | Val Acc: 69.95%\n",
            "epoch 5\n",
            "tensor(0.7156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6103, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6209, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5815, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5123, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8541, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5928, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6603, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5153, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7045, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5353, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8092, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5805, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6565, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5579, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6346, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6006, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5071, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5395, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7417, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5993, grad_fn=<NllLossBackward0>)\n",
            "Epoch   5 | Train Loss: 0.62 | Train Acc: 66.71% | Val Loss: 0.60 | Val Acc: 69.96%\n",
            "epoch 6\n",
            "tensor(0.6123, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5460, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5735, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5340, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4747, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5031, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4998, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6681, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6304, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7008, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6434, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5985, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8466, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5858, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5749, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4775, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6728, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5537, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4277, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6396, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5403, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6237, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6519, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5849, grad_fn=<NllLossBackward0>)\n",
            "Epoch   6 | Train Loss: 0.59 | Train Acc: 69.87% | Val Loss: 0.60 | Val Acc: 71.79%\n",
            "epoch 7\n",
            "tensor(0.4629, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7286, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4926, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7513, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5571, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5178, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7053, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5028, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7774, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6282, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5195, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9264, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6920, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5724, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6520, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5773, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5572, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4711, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6318, grad_fn=<NllLossBackward0>)\n",
            "Epoch   7 | Train Loss: 0.60 | Train Acc: 67.82% | Val Loss: 0.59 | Val Acc: 74.45%\n",
            "epoch 8\n",
            "tensor(0.4996, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6562, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5608, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5802, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5499, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5940, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5144, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5436, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5376, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5148, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5027, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5368, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5472, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5197, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5463, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6033, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6527, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5010, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4825, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6084, grad_fn=<NllLossBackward0>)\n",
            "Epoch   8 | Train Loss: 0.57 | Train Acc: 68.80% | Val Loss: 0.58 | Val Acc: 74.45%\n",
            "epoch 9\n",
            "tensor(0.5233, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5805, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6318, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6990, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5472, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5992, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5253, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4760, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7936, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5867, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5715, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5160, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6333, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6916, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5524, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5384, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5634, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6003, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5960, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4640, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5797, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6909, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5990, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5469, grad_fn=<NllLossBackward0>)\n",
            "Epoch   9 | Train Loss: 0.58 | Train Acc: 69.57% | Val Loss: 0.57 | Val Acc: 74.90%\n",
            "epoch 10\n",
            "tensor(0.5373, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7120, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6362, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6322, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4241, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5737, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5396, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4917, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5130, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5091, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5550, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5818, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5005, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7727, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6669, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6489, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5050, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6614, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6377, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4429, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7694, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5768, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5219, grad_fn=<NllLossBackward0>)\n",
            "Epoch  10 | Train Loss: 0.58 | Train Acc: 71.25% | Val Loss: 0.56 | Val Acc: 73.96%\n",
            "epoch 11\n",
            "tensor(0.6128, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5090, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5682, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6253, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6525, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6147, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6874, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3906, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4370, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3849, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6193, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5148, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6226, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6270, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5763, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5554, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6077, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5139, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5737, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5692, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5162, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6044, grad_fn=<NllLossBackward0>)\n",
            "Epoch  11 | Train Loss: 0.58 | Train Acc: 70.97% | Val Loss: 0.59 | Val Acc: 70.88%\n",
            "epoch 12\n",
            "tensor(0.6147, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5729, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5245, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4942, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4655, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6543, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5438, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6823, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6101, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4424, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5824, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7538, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6158, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5746, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5834, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5180, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4655, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5740, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5966, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4907, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5871, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4922, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4349, grad_fn=<NllLossBackward0>)\n",
            "Epoch  12 | Train Loss: 0.57 | Train Acc: 71.69% | Val Loss: 0.55 | Val Acc: 74.52%\n",
            "epoch 13\n",
            "tensor(0.5960, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5786, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5151, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4570, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4937, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5225, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6558, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5354, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5252, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5842, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6121, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5841, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5982, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6100, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6426, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6177, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5113, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5801, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5392, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6077, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5364, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5433, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5377, grad_fn=<NllLossBackward0>)\n",
            "Epoch  13 | Train Loss: 0.57 | Train Acc: 72.59% | Val Loss: 0.55 | Val Acc: 75.37%\n",
            "epoch 14\n",
            "tensor(0.4517, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6130, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5289, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7138, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6744, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7749, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6180, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5244, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4888, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6284, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4591, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5650, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5020, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6233, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6193, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5468, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5570, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5909, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5279, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4737, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4097, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5336, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5471, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5504, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4833, grad_fn=<NllLossBackward0>)\n",
            "Epoch  14 | Train Loss: 0.57 | Train Acc: 72.75% | Val Loss: 0.58 | Val Acc: 73.53%\n",
            "epoch 15\n",
            "tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5171, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5975, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5254, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8447, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5805, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6019, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7189, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6607, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6134, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4794, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5608, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5439, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4663, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5375, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4675, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4173, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5239, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6064, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4978, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7302, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4956, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5721, grad_fn=<NllLossBackward0>)\n",
            "Epoch  15 | Train Loss: 0.57 | Train Acc: 72.40% | Val Loss: 0.55 | Val Acc: 74.45%\n",
            "epoch 16\n",
            "tensor(0.5486, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5117, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6737, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5082, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6007, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7170, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5501, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5295, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5512, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6630, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6200, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5294, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5075, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6257, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5333, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5995, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5973, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5285, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5034, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6322, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5396, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5732, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5778, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3975, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5150, grad_fn=<NllLossBackward0>)\n",
            "Epoch  16 | Train Loss: 0.56 | Train Acc: 73.48% | Val Loss: 0.54 | Val Acc: 75.27%\n",
            "epoch 17\n",
            "tensor(0.5258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5347, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4946, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6056, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6277, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4571, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5261, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5523, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6005, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4860, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4303, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7855, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5889, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5072, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6927, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6433, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5131, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6606, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4781, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6905, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6131, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5403, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4031, grad_fn=<NllLossBackward0>)\n",
            "Epoch  17 | Train Loss: 0.57 | Train Acc: 72.97% | Val Loss: 0.55 | Val Acc: 73.06%\n",
            "epoch 18\n",
            "tensor(0.4411, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5502, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5046, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5714, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5980, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4590, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5681, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5364, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6603, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5870, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5542, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5951, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5188, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6237, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5124, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5073, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6488, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6089, grad_fn=<NllLossBackward0>)\n",
            "Epoch  18 | Train Loss: 0.55 | Train Acc: 74.77% | Val Loss: 0.56 | Val Acc: 73.16%\n",
            "epoch 19\n",
            "tensor(0.4658, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5307, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5872, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4978, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5591, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6064, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4678, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4638, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5810, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6344, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5062, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6177, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4928, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6243, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4641, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5420, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5785, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4780, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5255, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5262, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5531, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6790, grad_fn=<NllLossBackward0>)\n",
            "Epoch  19 | Train Loss: 0.54 | Train Acc: 74.35% | Val Loss: 0.56 | Val Acc: 75.36%\n",
            "epoch 20\n",
            "tensor(0.6241, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5582, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4592, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4933, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5429, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5547, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5046, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6264, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5876, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4461, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5155, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4867, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3604, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7018, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4996, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6023, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7474, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4512, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6302, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6089, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5312, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7287, grad_fn=<NllLossBackward0>)\n",
            "Epoch  20 | Train Loss: 0.56 | Train Acc: 73.12% | Val Loss: 0.55 | Val Acc: 75.84%\n",
            "epoch 21\n",
            "tensor(0.6853, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5614, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5483, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4751, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5072, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4001, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6342, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5538, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5089, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5650, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5354, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5513, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5547, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5938, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5965, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5492, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5675, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5315, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6370, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5703, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5002, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward0>)\n",
            "Epoch  21 | Train Loss: 0.57 | Train Acc: 72.17% | Val Loss: 0.55 | Val Acc: 72.64%\n",
            "epoch 22\n",
            "tensor(0.7243, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5018, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5554, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5303, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6098, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4511, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5409, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5575, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5372, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5399, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5996, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4691, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5497, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3955, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4717, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5502, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5301, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5822, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3693, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5408, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5449, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6537, grad_fn=<NllLossBackward0>)\n",
            "Epoch  22 | Train Loss: 0.55 | Train Acc: 72.85% | Val Loss: 0.55 | Val Acc: 75.33%\n",
            "epoch 23\n",
            "tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4729, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6464, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4569, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5445, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7218, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5638, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5754, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6110, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5689, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5887, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5153, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5605, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5627, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5389, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5458, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5694, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4954, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5284, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6005, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4767, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5140, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4961, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6229, grad_fn=<NllLossBackward0>)\n",
            "Epoch  23 | Train Loss: 0.56 | Train Acc: 71.81% | Val Loss: 0.54 | Val Acc: 75.79%\n",
            "epoch 24\n",
            "tensor(0.5944, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5750, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4886, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7227, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5521, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6092, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5831, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5595, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5288, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4715, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5330, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6145, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5188, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6021, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6042, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4841, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4821, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.0400, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7723, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6065, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5768, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4947, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4334, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5881, grad_fn=<NllLossBackward0>)\n",
            "Epoch  24 | Train Loss: 0.58 | Train Acc: 72.56% | Val Loss: 0.56 | Val Acc: 74.86%\n",
            "epoch 25\n",
            "tensor(0.6440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5891, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6464, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6000, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5948, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4865, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5816, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4344, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6372, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4333, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5413, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5045, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5245, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4417, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5848, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5034, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4256, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5074, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4052, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7422, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4257, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5841, grad_fn=<NllLossBackward0>)\n",
            "Epoch  25 | Train Loss: 0.55 | Train Acc: 73.48% | Val Loss: 0.54 | Val Acc: 75.82%\n",
            "epoch 26\n",
            "tensor(0.6231, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6448, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4945, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5551, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5185, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6235, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4942, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4271, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4491, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4880, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5068, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4436, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5203, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5320, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5117, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5418, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7441, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6216, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6202, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5728, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5573, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6306, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4885, grad_fn=<NllLossBackward0>)\n",
            "Epoch  26 | Train Loss: 0.55 | Train Acc: 74.18% | Val Loss: 0.54 | Val Acc: 74.40%\n",
            "epoch 27\n",
            "tensor(0.4391, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3762, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6136, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5582, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6408, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4599, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6010, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4392, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5034, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6843, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5200, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6255, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6288, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5618, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6070, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5814, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5062, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5443, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6253, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4504, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5930, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5469, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4958, grad_fn=<NllLossBackward0>)\n",
            "Epoch  27 | Train Loss: 0.55 | Train Acc: 72.66% | Val Loss: 0.53 | Val Acc: 75.85%\n",
            "epoch 28\n",
            "tensor(0.5440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5173, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4784, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5923, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4233, grad_fn=<NllLossBackward0>)\n",
            "tensor(1.1026, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7194, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5687, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6175, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6215, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6148, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5002, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5199, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4338, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8124, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6336, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6075, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5417, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5110, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4933, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5509, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5460, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5273, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5439, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5839, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5535, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5553, grad_fn=<NllLossBackward0>)\n",
            "Epoch  28 | Train Loss: 0.58 | Train Acc: 71.28% | Val Loss: 0.55 | Val Acc: 77.58%\n",
            "epoch 29\n",
            "tensor(0.6354, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5088, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6692, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5426, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5383, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6132, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5861, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5551, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5285, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5885, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5080, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5072, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5790, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4693, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4239, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5183, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5240, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5741, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6199, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4743, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4906, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6576, grad_fn=<NllLossBackward0>)\n",
            "Epoch  29 | Train Loss: 0.55 | Train Acc: 73.95% | Val Loss: 0.54 | Val Acc: 76.18%\n",
            "epoch 30\n",
            "tensor(0.5389, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5493, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6906, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4663, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5575, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5399, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5694, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4933, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6647, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4625, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5670, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5289, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5439, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4660, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7582, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4413, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7261, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5635, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6586, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5750, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4424, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4330, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5283, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5064, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7116, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5869, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5560, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5619, grad_fn=<NllLossBackward0>)\n",
            "Epoch  30 | Train Loss: 0.56 | Train Acc: 72.59% | Val Loss: 0.54 | Val Acc: 74.41%\n",
            "epoch 31\n",
            "tensor(0.4379, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4683, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5005, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6273, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6338, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5137, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6282, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6246, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6138, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5140, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4885, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5930, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5390, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7145, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5207, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5063, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4681, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4902, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5998, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5352, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5629, grad_fn=<NllLossBackward0>)\n",
            "Epoch  31 | Train Loss: 0.57 | Train Acc: 70.58% | Val Loss: 0.54 | Val Acc: 74.47%\n",
            "epoch 32\n",
            "tensor(0.6343, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4568, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5421, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5987, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5435, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5662, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6013, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5656, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7021, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5609, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5589, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5531, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5883, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7912, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4960, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5519, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7027, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5144, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6132, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4626, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4543, grad_fn=<NllLossBackward0>)\n",
            "Epoch  32 | Train Loss: 0.56 | Train Acc: 71.86% | Val Loss: 0.54 | Val Acc: 72.65%\n",
            "epoch 33\n",
            "tensor(0.5695, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4869, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3600, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5216, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7595, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5024, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5193, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5504, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5698, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5783, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5161, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5563, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5657, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4611, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4721, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5444, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5790, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4822, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6613, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5267, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5546, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5922, grad_fn=<NllLossBackward0>)\n",
            "Epoch  33 | Train Loss: 0.56 | Train Acc: 73.43% | Val Loss: 0.53 | Val Acc: 75.81%\n",
            "epoch 34\n",
            "tensor(0.6132, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5563, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5084, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4517, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5319, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5098, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5404, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5450, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5979, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6012, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4953, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4558, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4823, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6562, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5280, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4875, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5170, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5366, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4913, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5090, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
            "Epoch  34 | Train Loss: 0.54 | Train Acc: 72.90% | Val Loss: 0.56 | Val Acc: 72.15%\n",
            "epoch 35\n",
            "tensor(0.3923, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5101, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5946, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5550, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5042, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5061, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4036, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5188, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6668, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5154, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4216, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5843, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5464, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5698, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4691, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4627, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6234, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5448, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6316, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6049, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6006, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5975, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5749, grad_fn=<NllLossBackward0>)\n",
            "Epoch  35 | Train Loss: 0.54 | Train Acc: 74.15% | Val Loss: 0.54 | Val Acc: 73.55%\n",
            "epoch 36\n",
            "tensor(0.4977, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5326, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4733, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6643, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5128, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5707, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4373, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6678, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4700, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4577, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3831, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5723, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5274, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5022, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5912, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6509, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5087, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5896, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4916, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5772, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6048, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5394, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5500, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6611, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5614, grad_fn=<NllLossBackward0>)\n",
            "Epoch  36 | Train Loss: 0.55 | Train Acc: 73.82% | Val Loss: 0.54 | Val Acc: 77.58%\n",
            "epoch 37\n",
            "tensor(0.6082, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4898, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5488, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5162, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5403, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5094, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6275, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5977, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6149, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5122, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5981, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5084, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6117, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5282, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5955, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5832, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5300, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6150, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4116, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4795, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4720, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4772, grad_fn=<NllLossBackward0>)\n",
            "Epoch  37 | Train Loss: 0.54 | Train Acc: 73.23% | Val Loss: 0.52 | Val Acc: 77.13%\n",
            "epoch 38\n",
            "tensor(0.5389, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6295, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5855, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6089, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6317, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6013, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4246, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5498, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5098, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5148, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4148, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5485, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6191, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5105, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4812, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4771, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4681, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5520, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5592, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5376, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5821, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5093, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4545, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6174, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5711, grad_fn=<NllLossBackward0>)\n",
            "Epoch  38 | Train Loss: 0.55 | Train Acc: 72.85% | Val Loss: 0.55 | Val Acc: 74.50%\n",
            "epoch 39\n",
            "tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5467, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6542, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5296, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4968, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4701, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4903, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3862, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7363, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6056, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5175, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5765, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5775, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4133, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5286, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4610, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5904, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5015, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4598, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7981, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4955, grad_fn=<NllLossBackward0>)\n",
            "Epoch  39 | Train Loss: 0.55 | Train Acc: 73.21% | Val Loss: 0.53 | Val Acc: 77.62%\n",
            "epoch 40\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6179, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6146, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5786, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6173, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5560, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6481, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5361, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5245, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6278, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4509, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5024, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5982, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5580, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5583, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6468, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6270, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4804, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5701, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5664, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4752, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5226, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4467, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5296, grad_fn=<NllLossBackward0>)\n",
            "Epoch  40 | Train Loss: 0.55 | Train Acc: 73.36% | Val Loss: 0.53 | Val Acc: 76.68%\n",
            "epoch 41\n",
            "tensor(0.6206, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5595, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4828, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5431, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4707, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5629, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4464, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4903, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4263, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6293, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5709, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4633, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6072, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5732, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6206, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5058, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6524, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7386, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4877, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5675, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5757, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5455, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5202, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4574, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4391, grad_fn=<NllLossBackward0>)\n",
            "Epoch  41 | Train Loss: 0.54 | Train Acc: 73.22% | Val Loss: 0.57 | Val Acc: 70.36%\n",
            "epoch 42\n",
            "tensor(0.5591, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5014, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5269, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4977, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5840, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4325, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5079, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6838, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4878, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4686, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5073, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6702, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5791, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5317, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5836, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5171, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5671, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5398, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5774, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5139, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5423, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5966, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5314, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4884, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6150, grad_fn=<NllLossBackward0>)\n",
            "Epoch  42 | Train Loss: 0.54 | Train Acc: 73.26% | Val Loss: 0.53 | Val Acc: 76.15%\n",
            "epoch 43\n",
            "tensor(0.4962, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5698, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5548, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6706, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6649, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6080, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3622, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4010, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5662, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5836, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6291, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5424, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4960, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5364, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6100, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5628, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5194, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5224, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5363, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4446, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4585, grad_fn=<NllLossBackward0>)\n",
            "Epoch  43 | Train Loss: 0.56 | Train Acc: 72.39% | Val Loss: 0.55 | Val Acc: 73.06%\n",
            "epoch 44\n",
            "tensor(0.3606, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6827, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4622, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5399, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4111, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8274, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6115, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4789, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7203, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5717, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5215, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5711, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6031, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4758, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5782, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6604, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7008, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5507, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3834, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3937, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4900, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4361, grad_fn=<NllLossBackward0>)\n",
            "Epoch  44 | Train Loss: 0.55 | Train Acc: 74.45% | Val Loss: 0.63 | Val Acc: 68.65%\n",
            "epoch 45\n",
            "tensor(0.7805, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6205, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5687, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4785, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5000, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5250, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4884, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5494, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6052, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4555, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6934, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6424, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5573, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5973, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5408, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5053, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4124, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8346, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6638, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4260, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5354, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6413, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4761, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4922, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6460, grad_fn=<NllLossBackward0>)\n",
            "Epoch  45 | Train Loss: 0.57 | Train Acc: 72.36% | Val Loss: 0.53 | Val Acc: 77.64%\n",
            "epoch 46\n",
            "tensor(0.5050, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5277, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5090, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5834, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5152, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5746, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4868, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4798, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7048, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6316, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6475, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5767, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5783, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5636, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6018, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5093, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5226, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5583, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5978, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5709, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4382, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5138, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4967, grad_fn=<NllLossBackward0>)\n",
            "Epoch  46 | Train Loss: 0.55 | Train Acc: 74.76% | Val Loss: 0.52 | Val Acc: 76.18%\n",
            "epoch 47\n",
            "tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5922, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4277, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5373, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6742, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5505, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5580, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4980, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5686, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4207, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7033, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5902, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5918, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4698, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4967, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4402, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5178, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5550, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7900, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5263, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5032, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4855, grad_fn=<NllLossBackward0>)\n",
            "Epoch  47 | Train Loss: 0.55 | Train Acc: 72.59% | Val Loss: 0.55 | Val Acc: 73.10%\n",
            "epoch 48\n",
            "tensor(0.6995, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5025, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5188, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4950, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4454, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4630, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5918, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7623, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5882, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5869, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5143, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4721, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5761, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3434, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3963, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6514, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6567, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5476, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6883, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5449, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6017, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4802, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4680, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5491, grad_fn=<NllLossBackward0>)\n",
            "Epoch  48 | Train Loss: 0.55 | Train Acc: 73.57% | Val Loss: 0.54 | Val Acc: 71.73%\n",
            "epoch 49\n",
            "tensor(0.5826, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4976, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5678, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6085, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5038, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7061, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5310, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4468, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5994, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5694, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4893, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5030, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5742, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5859, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4375, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4992, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5009, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4317, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6048, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6895, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6681, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4580, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4157, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6289, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6751, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5889, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6516, grad_fn=<NllLossBackward0>)\n",
            "Epoch  49 | Train Loss: 0.56 | Train Acc: 74.29% | Val Loss: 0.54 | Val Acc: 75.39%\n",
            "epoch 50\n",
            "tensor(0.5233, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5794, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5536, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5313, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6070, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6044, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5647, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5275, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4905, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4776, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3918, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8012, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5701, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5174, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5211, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4580, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4890, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5703, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6571, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4632, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5779, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4401, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5346, grad_fn=<NllLossBackward0>)\n",
            "Epoch  50 | Train Loss: 0.55 | Train Acc: 72.98% | Val Loss: 0.52 | Val Acc: 78.04%\n",
            "epoch 51\n",
            "tensor(0.4837, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5459, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6039, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6735, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5495, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4489, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4870, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5647, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4011, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5144, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7075, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4362, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5227, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5487, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3379, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9027, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6023, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4518, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6705, grad_fn=<NllLossBackward0>)\n",
            "Epoch  51 | Train Loss: 0.55 | Train Acc: 74.82% | Val Loss: 0.58 | Val Acc: 70.90%\n",
            "epoch 52\n",
            "tensor(0.5222, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6062, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4839, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5521, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5103, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4495, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4619, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4874, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4546, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4606, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5958, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4854, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3815, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8449, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7041, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5121, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5423, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5832, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5497, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5050, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5868, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5952, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5831, grad_fn=<NllLossBackward0>)\n",
            "Epoch  52 | Train Loss: 0.54 | Train Acc: 73.99% | Val Loss: 0.55 | Val Acc: 73.99%\n",
            "epoch 53\n",
            "tensor(0.5400, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5641, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7120, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6423, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5807, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5723, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4570, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4871, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5417, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5223, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5236, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5446, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4085, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6397, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4374, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6296, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5362, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4841, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5690, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6490, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
            "Epoch  53 | Train Loss: 0.54 | Train Acc: 72.56% | Val Loss: 0.53 | Val Acc: 75.35%\n",
            "epoch 54\n",
            "tensor(0.5892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5110, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4380, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3989, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5374, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6871, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4695, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5513, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5078, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5539, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6659, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5547, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5678, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5228, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6329, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6880, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3279, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5358, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6490, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5839, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5422, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5393, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5433, grad_fn=<NllLossBackward0>)\n",
            "Epoch  54 | Train Loss: 0.55 | Train Acc: 74.71% | Val Loss: 0.55 | Val Acc: 72.21%\n",
            "epoch 55\n",
            "tensor(0.4762, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4463, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6084, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4931, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6383, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5827, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4406, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4659, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6101, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5498, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6163, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4377, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5639, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4618, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4929, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5016, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4155, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7193, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5487, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6500, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5498, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6832, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
            "Epoch  55 | Train Loss: 0.55 | Train Acc: 73.39% | Val Loss: 0.54 | Val Acc: 76.64%\n",
            "epoch 56\n",
            "tensor(0.5822, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5030, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5626, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5614, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4552, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5633, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4070, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5934, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4397, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5398, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5546, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6101, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5080, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4722, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6319, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7301, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5365, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4764, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6459, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5076, grad_fn=<NllLossBackward0>)\n",
            "Epoch  56 | Train Loss: 0.55 | Train Acc: 72.55% | Val Loss: 0.56 | Val Acc: 72.21%\n",
            "epoch 57\n",
            "tensor(0.4708, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5458, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4620, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5725, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5906, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5161, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4669, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7345, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5650, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5655, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4643, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5422, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5076, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6135, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5492, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5115, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5986, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5366, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4885, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6625, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7177, grad_fn=<NllLossBackward0>)\n",
            "Epoch  57 | Train Loss: 0.54 | Train Acc: 73.02% | Val Loss: 0.54 | Val Acc: 77.16%\n",
            "epoch 58\n",
            "tensor(0.5487, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5659, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6792, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4709, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5410, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5980, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5826, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5418, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6463, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5207, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6478, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4935, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7576, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5275, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5873, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4568, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4593, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6207, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3615, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5394, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4756, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5360, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6656, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6541, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5952, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6086, grad_fn=<NllLossBackward0>)\n",
            "Epoch  58 | Train Loss: 0.57 | Train Acc: 72.29% | Val Loss: 0.54 | Val Acc: 77.62%\n",
            "epoch 59\n",
            "tensor(0.5426, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5824, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4994, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4395, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5168, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4685, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3953, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5533, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6443, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5121, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4587, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4631, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5501, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5936, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6391, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5990, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4686, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5627, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5413, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7197, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5252, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5338, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6248, grad_fn=<NllLossBackward0>)\n",
            "Epoch  59 | Train Loss: 0.54 | Train Acc: 73.60% | Val Loss: 0.54 | Val Acc: 72.65%\n",
            "epoch 60\n",
            "tensor(0.4932, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5212, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5135, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5856, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5237, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5654, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5568, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4998, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6111, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5631, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5330, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5137, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6125, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5349, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4736, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6530, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6271, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5207, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4184, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5712, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6884, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4913, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4169, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6972, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6478, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6682, grad_fn=<NllLossBackward0>)\n",
            "Epoch  60 | Train Loss: 0.56 | Train Acc: 73.04% | Val Loss: 0.57 | Val Acc: 70.87%\n",
            "epoch 61\n",
            "tensor(0.5465, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4967, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6271, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5890, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4839, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4888, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5366, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4905, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7381, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5391, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6244, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4346, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5170, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5403, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4633, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5981, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5615, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4229, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4533, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4361, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5171, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6397, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6625, grad_fn=<NllLossBackward0>)\n",
            "Epoch  61 | Train Loss: 0.55 | Train Acc: 73.69% | Val Loss: 0.53 | Val Acc: 74.44%\n",
            "epoch 62\n",
            "tensor(0.4831, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5774, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5236, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5284, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6537, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5563, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5677, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5942, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5435, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5305, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5716, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5577, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6081, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5687, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5328, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5057, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5319, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7149, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5593, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3896, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4357, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6267, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6491, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5571, grad_fn=<NllLossBackward0>)\n",
            "Epoch  62 | Train Loss: 0.54 | Train Acc: 74.06% | Val Loss: 0.52 | Val Acc: 76.70%\n",
            "epoch 63\n",
            "tensor(0.4625, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5219, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5105, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4377, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5044, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6229, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6783, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5235, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5645, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5092, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4769, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5519, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4862, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4767, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6662, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4900, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5558, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5232, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5507, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4596, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4698, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7529, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6356, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6226, grad_fn=<NllLossBackward0>)\n",
            "Epoch  63 | Train Loss: 0.54 | Train Acc: 73.76% | Val Loss: 0.53 | Val Acc: 73.10%\n",
            "epoch 64\n",
            "tensor(0.5824, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4818, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5003, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6131, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6344, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5375, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5666, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5475, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4505, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5265, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8319, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6794, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4168, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5100, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5849, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6034, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5044, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7097, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5813, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5396, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4954, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6212, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5307, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4916, grad_fn=<NllLossBackward0>)\n",
            "Epoch  64 | Train Loss: 0.56 | Train Acc: 71.52% | Val Loss: 0.53 | Val Acc: 72.19%\n",
            "epoch 65\n",
            "tensor(0.5381, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4162, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5142, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4736, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7023, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6270, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4370, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5348, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5440, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5594, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5332, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5781, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4736, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6152, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5907, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6550, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8103, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6149, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5145, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3793, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4334, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5367, grad_fn=<NllLossBackward0>)\n",
            "Epoch  65 | Train Loss: 0.55 | Train Acc: 73.68% | Val Loss: 0.61 | Val Acc: 70.87%\n",
            "epoch 66\n",
            "tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3991, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5974, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6424, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6474, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5850, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4499, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5918, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4532, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5139, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6533, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5020, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6556, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6679, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4719, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4755, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4313, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5119, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3314, grad_fn=<NllLossBackward0>)\n",
            "Epoch  66 | Train Loss: 0.53 | Train Acc: 72.91% | Val Loss: 0.62 | Val Acc: 71.31%\n",
            "epoch 67\n",
            "tensor(0.4679, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6300, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6763, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5189, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7986, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6184, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5516, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5028, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4456, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5779, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5636, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4837, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5858, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6650, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5580, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4588, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4630, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4381, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4838, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7074, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6598, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5590, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5143, grad_fn=<NllLossBackward0>)\n",
            "Epoch  67 | Train Loss: 0.56 | Train Acc: 71.39% | Val Loss: 0.55 | Val Acc: 71.75%\n",
            "epoch 68\n",
            "tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5375, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5928, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5479, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3530, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5548, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4891, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5022, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5300, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6313, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5555, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6055, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4477, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4539, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5708, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7060, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6227, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5408, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4610, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6275, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5872, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6358, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5976, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5577, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4212, grad_fn=<NllLossBackward0>)\n",
            "Epoch  68 | Train Loss: 0.55 | Train Acc: 72.53% | Val Loss: 0.54 | Val Acc: 71.28%\n",
            "epoch 69\n",
            "tensor(0.4705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5927, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4674, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6044, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6754, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4801, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6515, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5392, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5717, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5814, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5237, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4176, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4039, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5516, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6244, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6889, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5925, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4881, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5265, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4282, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5401, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6051, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5611, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5446, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8887, grad_fn=<NllLossBackward0>)\n",
            "Epoch  69 | Train Loss: 0.55 | Train Acc: 73.88% | Val Loss: 0.62 | Val Acc: 62.82%\n",
            "epoch 70\n",
            "tensor(0.5619, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6177, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4927, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5012, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4562, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4793, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4005, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4721, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4070, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4523, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6460, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6898, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5293, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4724, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5249, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5278, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6418, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6834, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5537, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4657, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5586, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4397, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6956, grad_fn=<NllLossBackward0>)\n",
            "Epoch  70 | Train Loss: 0.54 | Train Acc: 72.60% | Val Loss: 0.52 | Val Acc: 75.81%\n",
            "epoch 71\n",
            "tensor(0.4310, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4732, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6371, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5557, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5658, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5218, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5807, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5785, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6130, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5343, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4695, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6964, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5630, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3315, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4835, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6383, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5179, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6307, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5123, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4945, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5547, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6690, grad_fn=<NllLossBackward0>)\n",
            "Epoch  71 | Train Loss: 0.54 | Train Acc: 72.26% | Val Loss: 0.56 | Val Acc: 72.19%\n",
            "epoch 72\n",
            "tensor(0.4393, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4945, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4953, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6967, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5815, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4741, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4477, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4006, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5499, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6356, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6285, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5789, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6106, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6315, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4592, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3763, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7058, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6824, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5360, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6896, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4279, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6185, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5167, grad_fn=<NllLossBackward0>)\n",
            "Epoch  72 | Train Loss: 0.55 | Train Acc: 72.48% | Val Loss: 0.53 | Val Acc: 75.73%\n",
            "epoch 73\n",
            "tensor(0.5166, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5706, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5975, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5143, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6416, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5010, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4798, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4849, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3668, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4826, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5223, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6092, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3818, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7850, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4468, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5749, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5326, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4886, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6274, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6634, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5604, grad_fn=<NllLossBackward0>)\n",
            "Epoch  73 | Train Loss: 0.54 | Train Acc: 74.04% | Val Loss: 0.53 | Val Acc: 72.21%\n",
            "epoch 74\n",
            "tensor(0.4675, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4778, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5612, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4672, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7498, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5316, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4589, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4699, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5935, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5632, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5426, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7191, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4518, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6665, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4721, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4261, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4078, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5633, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6199, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5435, grad_fn=<NllLossBackward0>)\n",
            "Epoch  74 | Train Loss: 0.54 | Train Acc: 74.79% | Val Loss: 0.57 | Val Acc: 70.82%\n",
            "epoch 75\n",
            "tensor(0.5720, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5224, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4772, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4814, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5393, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4504, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8030, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5795, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5102, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5822, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5079, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5149, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4896, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4402, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4084, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5374, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5135, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4365, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5078, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5636, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6893, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6213, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5532, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5465, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5042, grad_fn=<NllLossBackward0>)\n",
            "Epoch  75 | Train Loss: 0.54 | Train Acc: 74.40% | Val Loss: 0.52 | Val Acc: 75.29%\n",
            "epoch 76\n",
            "tensor(0.5710, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4696, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4881, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4944, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4760, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5046, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4240, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7435, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6534, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4407, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6430, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5206, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5819, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5133, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5278, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5444, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6323, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5432, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7030, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5680, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6081, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7149, grad_fn=<NllLossBackward0>)\n",
            "Epoch  76 | Train Loss: 0.56 | Train Acc: 73.96% | Val Loss: 0.54 | Val Acc: 71.26%\n",
            "epoch 77\n",
            "tensor(0.5717, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5329, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6486, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4139, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6021, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7171, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5465, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5579, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6612, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5106, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4649, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4747, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5311, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5941, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5192, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5065, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5987, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6430, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5528, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4833, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4966, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4914, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4711, grad_fn=<NllLossBackward0>)\n",
            "Epoch  77 | Train Loss: 0.55 | Train Acc: 72.64% | Val Loss: 0.52 | Val Acc: 77.19%\n",
            "epoch 78\n",
            "tensor(0.6153, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5125, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6213, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4063, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4866, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5454, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4954, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5404, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5142, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6075, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4909, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4948, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8300, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5897, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6328, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5919, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5668, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6130, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5817, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6249, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6007, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5036, grad_fn=<NllLossBackward0>)\n",
            "Epoch  78 | Train Loss: 0.56 | Train Acc: 72.95% | Val Loss: 0.55 | Val Acc: 71.27%\n",
            "epoch 79\n",
            "tensor(0.3901, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5256, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5178, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4496, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7235, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4902, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5037, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5299, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6663, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4786, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5002, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6032, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5893, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5477, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5783, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7312, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5622, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4915, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5437, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5240, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4236, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6434, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5529, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4956, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4750, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5471, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6076, grad_fn=<NllLossBackward0>)\n",
            "Epoch  79 | Train Loss: 0.55 | Train Acc: 73.88% | Val Loss: 0.53 | Val Acc: 75.35%\n",
            "epoch 80\n",
            "tensor(0.4115, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5911, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6056, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6053, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6217, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6710, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6357, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4595, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5848, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5321, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6051, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4628, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5854, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5088, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4628, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4713, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5128, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8307, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5978, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4262, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5476, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4876, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5183, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4741, grad_fn=<NllLossBackward0>)\n",
            "Epoch  80 | Train Loss: 0.55 | Train Acc: 72.97% | Val Loss: 0.53 | Val Acc: 76.20%\n",
            "epoch 81\n",
            "tensor(0.8458, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6507, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3085, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4946, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7187, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5456, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5344, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6282, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5150, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4787, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5533, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4510, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8649, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5953, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6277, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5609, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6892, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5318, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6107, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4296, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4547, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5212, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5649, grad_fn=<NllLossBackward0>)\n",
            "Epoch  81 | Train Loss: 0.56 | Train Acc: 73.20% | Val Loss: 0.52 | Val Acc: 77.10%\n",
            "epoch 82\n",
            "tensor(0.3889, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5214, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6752, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5055, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7121, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5524, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5054, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5032, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3783, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5987, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5329, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4768, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5668, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5689, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5510, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6166, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5213, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5006, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5389, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6099, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4964, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4516, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5697, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6213, grad_fn=<NllLossBackward0>)\n",
            "Epoch  82 | Train Loss: 0.53 | Train Acc: 73.65% | Val Loss: 0.57 | Val Acc: 71.30%\n",
            "epoch 83\n",
            "tensor(0.4442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7058, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6262, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5451, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5422, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6568, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5927, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5823, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5503, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7403, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5208, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6031, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4538, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5588, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4459, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5974, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5486, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4132, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6704, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5592, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4180, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4496, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5243, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5844, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5476, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5225, grad_fn=<NllLossBackward0>)\n",
            "Epoch  83 | Train Loss: 0.55 | Train Acc: 72.28% | Val Loss: 0.54 | Val Acc: 73.98%\n",
            "epoch 84\n",
            "tensor(0.6599, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5779, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4900, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3996, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5452, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6019, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5554, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5685, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5475, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7191, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5258, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5337, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4906, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5933, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4727, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5591, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5816, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5294, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3848, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4934, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6192, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5746, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5357, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6609, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4032, grad_fn=<NllLossBackward0>)\n",
            "Epoch  84 | Train Loss: 0.54 | Train Acc: 74.14% | Val Loss: 0.53 | Val Acc: 72.22%\n",
            "epoch 85\n",
            "tensor(0.5117, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4788, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4253, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3680, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5967, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7142, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5107, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4882, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4641, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4269, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5954, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4793, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6673, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5568, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2991, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7619, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6482, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5732, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4991, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5952, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6031, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4526, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5619, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5840, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6016, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5496, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4873, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4750, grad_fn=<NllLossBackward0>)\n",
            "Epoch  85 | Train Loss: 0.53 | Train Acc: 73.76% | Val Loss: 0.52 | Val Acc: 78.05%\n",
            "epoch 86\n",
            "tensor(0.5862, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5839, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6894, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5435, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5301, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7047, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5119, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4738, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6313, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5324, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4441, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7024, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4893, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5487, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5803, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5141, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5776, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8353, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6341, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5628, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4772, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5837, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4686, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4525, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5190, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5703, grad_fn=<NllLossBackward0>)\n",
            "Epoch  86 | Train Loss: 0.57 | Train Acc: 71.83% | Val Loss: 0.52 | Val Acc: 78.02%\n",
            "epoch 87\n",
            "tensor(0.3588, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5398, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6767, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5652, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6283, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4477, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4565, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6606, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5888, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5131, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5601, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4463, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6220, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5734, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5516, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5394, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5865, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4179, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5738, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6661, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5609, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4844, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5017, grad_fn=<NllLossBackward0>)\n",
            "Epoch  87 | Train Loss: 0.55 | Train Acc: 71.77% | Val Loss: 0.56 | Val Acc: 72.21%\n",
            "epoch 88\n",
            "tensor(0.4453, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7097, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5661, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6234, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4899, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5640, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5457, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5302, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4827, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4312, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5143, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5279, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6024, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6548, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4848, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7339, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5921, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4857, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4430, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7300, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5514, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5151, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4815, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4420, grad_fn=<NllLossBackward0>)\n",
            "Epoch  88 | Train Loss: 0.56 | Train Acc: 70.85% | Val Loss: 0.56 | Val Acc: 67.68%\n",
            "epoch 89\n",
            "tensor(0.5202, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5774, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5432, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4057, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5873, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4173, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7801, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4868, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4907, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5977, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5327, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4584, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5597, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5606, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5472, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4624, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6000, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6249, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5308, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5939, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5978, grad_fn=<NllLossBackward0>)\n",
            "Epoch  89 | Train Loss: 0.56 | Train Acc: 71.53% | Val Loss: 0.54 | Val Acc: 71.28%\n",
            "epoch 90\n",
            "tensor(0.5710, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5192, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5741, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4642, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4063, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5216, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5415, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3812, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5158, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4726, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6776, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5691, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5852, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4994, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5181, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6614, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6247, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5531, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6035, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5607, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4873, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6144, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5674, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4421, grad_fn=<NllLossBackward0>)\n",
            "Epoch  90 | Train Loss: 0.53 | Train Acc: 74.00% | Val Loss: 0.53 | Val Acc: 74.50%\n",
            "epoch 91\n",
            "tensor(0.5317, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6573, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4674, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4483, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5501, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5387, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6589, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5112, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4947, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5436, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4678, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6350, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6367, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4409, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6587, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5558, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5352, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5586, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5562, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4070, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7103, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5569, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4953, grad_fn=<NllLossBackward0>)\n",
            "Epoch  91 | Train Loss: 0.54 | Train Acc: 73.98% | Val Loss: 0.51 | Val Acc: 75.33%\n",
            "epoch 92\n",
            "tensor(0.5442, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4705, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5298, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5230, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5750, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5668, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6025, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5022, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6211, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6176, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4864, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3856, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.8515, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6197, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5976, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5009, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5289, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5295, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5587, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5374, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6164, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5057, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5964, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4298, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4752, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5438, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5992, grad_fn=<NllLossBackward0>)\n",
            "Epoch  92 | Train Loss: 0.56 | Train Acc: 72.70% | Val Loss: 0.57 | Val Acc: 72.64%\n",
            "epoch 93\n",
            "tensor(0.5715, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4405, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5809, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7212, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5701, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4534, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4535, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4689, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4287, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9303, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5981, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5850, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6197, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5812, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5156, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5762, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5157, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4659, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5714, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6281, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5715, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4474, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6199, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6008, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4272, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3978, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5734, grad_fn=<NllLossBackward0>)\n",
            "Epoch  93 | Train Loss: 0.55 | Train Acc: 73.37% | Val Loss: 0.64 | Val Acc: 66.39%\n",
            "epoch 94\n",
            "tensor(0.5338, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4775, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5733, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6144, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4513, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5137, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5665, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5690, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5679, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5359, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6041, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4532, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7338, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5170, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5108, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4847, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6051, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4813, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5548, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4379, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6412, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4985, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4585, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7392, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5557, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6153, grad_fn=<NllLossBackward0>)\n",
            "Epoch  94 | Train Loss: 0.55 | Train Acc: 75.71% | Val Loss: 0.54 | Val Acc: 77.59%\n",
            "epoch 95\n",
            "tensor(0.5969, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4379, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5817, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6524, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6293, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5123, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5788, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6445, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5914, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6317, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5358, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5615, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4692, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6203, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4268, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4232, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4673, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6728, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5370, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5804, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6090, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5625, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5074, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5257, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5246, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5351, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4897, grad_fn=<NllLossBackward0>)\n",
            "Epoch  95 | Train Loss: 0.55 | Train Acc: 73.78% | Val Loss: 0.60 | Val Acc: 70.84%\n",
            "epoch 96\n",
            "tensor(0.5006, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4480, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6077, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5325, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6084, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4851, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5624, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5818, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5260, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5010, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5891, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4646, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4776, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5237, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5047, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4137, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5934, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6553, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5983, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4342, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4816, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7349, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5610, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6029, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6040, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4750, grad_fn=<NllLossBackward0>)\n",
            "Epoch  96 | Train Loss: 0.55 | Train Acc: 73.11% | Val Loss: 0.56 | Val Acc: 72.16%\n",
            "epoch 97\n",
            "tensor(0.4645, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5666, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5089, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5489, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5565, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6268, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6205, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5004, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6050, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5825, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4635, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5882, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5741, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6065, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5609, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5949, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5232, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4989, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6506, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5189, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4700, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5497, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5309, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5349, grad_fn=<NllLossBackward0>)\n",
            "Epoch  97 | Train Loss: 0.55 | Train Acc: 73.21% | Val Loss: 0.54 | Val Acc: 76.68%\n",
            "epoch 98\n",
            "tensor(0.4667, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4799, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4617, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5286, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6083, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5796, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4330, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5796, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4752, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6411, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4855, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7007, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6268, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6222, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5742, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5866, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5466, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4759, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4432, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7196, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6809, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6500, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5741, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4881, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4831, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4895, grad_fn=<NllLossBackward0>)\n",
            "Epoch  98 | Train Loss: 0.55 | Train Acc: 73.56% | Val Loss: 0.59 | Val Acc: 72.21%\n",
            "epoch 99\n",
            "tensor(0.7796, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5450, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5255, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5690, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5637, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4325, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5583, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5483, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5214, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4428, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4123, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5613, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5938, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6600, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6172, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5718, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5730, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6269, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5354, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5400, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6162, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5392, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6924, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6286, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4824, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4973, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4555, grad_fn=<NllLossBackward0>)\n",
            "Epoch  99 | Train Loss: 0.56 | Train Acc: 74.00% | Val Loss: 0.64 | Val Acc: 69.57%\n",
            "epoch 100\n",
            "tensor(0.4710, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5638, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5126, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4570, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3908, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2946, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4712, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4400, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.9772, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6163, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6618, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6342, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6242, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5470, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5820, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4283, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5118, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5043, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3988, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.4756, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6739, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5384, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.7014, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6564, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.6142, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5581, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.5145, grad_fn=<NllLossBackward0>)\n",
            "Epoch 100 | Train Loss: 0.55 | Train Acc: 72.92% | Val Loss: 0.53 | Val Acc: 74.44%\n"
          ]
        }
      ],
      "source": [
        "egcn = GIN(dim_h=32)\n",
        "egcn = train(egcn, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcx2EWu307ZS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}